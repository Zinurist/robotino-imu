{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import samples as ls\n",
    "import model_types\n",
    "\n",
    "step_counter = 0\n",
    "load_dnn = False\n",
    "load_samples = False\n",
    "model_num = 101\n",
    "model_type = 11\n",
    "\n",
    "model_id = '%s_%s' % (model_type, model_num)\n",
    "labels,sample_ids,filename = model_types.get_labels(model_type)\n",
    "\n",
    "if model_num == 0:\n",
    "    input_dim = 6\n",
    "    hidden_layers = [50,10]\n",
    "elif model_num == 1:\n",
    "    input_dim = 6\n",
    "    hidden_layers = [50]\n",
    "elif model_num == 100:\n",
    "    input_dim = 6\n",
    "    hidden_layers = [50]\n",
    "elif model_num == 101:\n",
    "    input_dim = 6\n",
    "    hidden_layers = [20,20,20,20]\n",
    "else:\n",
    "    raise ValueError('Unknown model')\n",
    "\n",
    "hidden_layers.insert(0,50*input_dim)\n",
    "hidden_layers.append(1)\n",
    "   \n",
    "classes = len(labels)\n",
    "\n",
    "#percentage used for test data\n",
    "test_rate = 0.1\n",
    "\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'angle_0': 0.0, 'angle_120_r': -0.6666666666666666, 'angle_60_r': -0.3333333333333333, 'angle_90_l': 0.5, 'angle_90_r': -0.5, 'angle_120_l': 0.6666666666666666, 'angle_180': 1.0, 'angle_150_r': -0.8333333333333334, 'angle_30_r': -0.16666666666666666, 'angle_60_l': 0.3333333333333333, 'angle_30_l': 0.16666666666666666, 'angle_150_l': 0.8333333333333334}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import math\n",
    "\n",
    "#create dict to convert label to network output\n",
    "as_angle = {}\n",
    "as_degrees = {}\n",
    "as_radians = {}\n",
    "for label in labels:\n",
    "    vals = re.match(r'angle_(\\d*)(?:_(l|r))?', label).groups()\n",
    "    val = float(vals[0])/180\n",
    "    if vals[1] == 'r':\n",
    "        val = -val\n",
    "    as_angle[label] = val\n",
    "    as_degrees[label] = val*360\n",
    "    as_radians[label] = val*math.pi*2\n",
    "print(as_angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if load_samples:\n",
    "    samples = ls.load(filename)\n",
    "else:\n",
    "    samples = ls.Samples(labels)\n",
    "\n",
    "    for label in labels:\n",
    "        samples.load_samples(label = label, sample_ids = sample_ids)\n",
    "        \n",
    "    samples.convert_to_input(size = None, accel='xyz', gyro='xyz', compass='')\n",
    "    \n",
    "    ls.save(samples, filename)\n",
    "    \n",
    "samples.unroll(steps=50) #fixed for angle samples at 50 values\n",
    "samples.split_test(test_rate)\n",
    "samples.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "xtest,ytest,_ = samples.get_test(padding=False)\n",
    "xtest = np.array(xtest)\n",
    "ytest = np.array(ytest)\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 50*input_dim], name='x')\n",
    "y = tf.placeholder(tf.float32, [None], name='y')\n",
    "\n",
    "Ws = []\n",
    "for i in range(len(hidden_layers)-1):\n",
    "    W = tf.Variable(tf.random_normal([hidden_layers[i], hidden_layers[i+1]]))\n",
    "    b = tf.Variable(tf.zeros(hidden_layers[i+1]))\n",
    "    Ws.append((W,b))\n",
    "\n",
    "\n",
    "preactivations = []\n",
    "activations = []\n",
    "act = x\n",
    "for W,b in Ws:\n",
    "    preact = tf.matmul(act, W) + b\n",
    "    preactivations.append(preact)\n",
    "    act = tf.sigmoid(preact)\n",
    "    activations.append(act)\n",
    "dnn_angle = act\n",
    "\n",
    "#simple loss function\n",
    "loss = tf.reduce_mean(tf.square(tf.subtract(y, dnn_angle)))\n",
    "\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "optimizer = tf.train.AdamOptimizer().minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "#summaries\n",
    "def var_summary(var, name):\n",
    "    mean = tf.reduce_mean(var)\n",
    "    tf.summary.scalar(name + '_mean', mean)\n",
    "    stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "    tf.summary.scalar(name + '_stddev', stddev)\n",
    "    tf.summary.scalar(name + '_max', tf.reduce_max(var))\n",
    "    tf.summary.scalar(name + '_min', tf.reduce_min(var))\n",
    "    tf.summary.histogram(name + '_histogram', var)\n",
    "i = 0\n",
    "for W,b in Ws: \n",
    "    var_summary(W, 'weights_%s' % i)\n",
    "    var_summary(b, 'bias_%s' % i)\n",
    "    i += 1\n",
    "for i in range(len(activations)):\n",
    "    tf.summary.histogram('preactivations_%s' % i, preactivations[i])\n",
    "    tf.summary.histogram('activations_%s' % i, activations[i])\n",
    "tf.summary.scalar('loss', loss)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter('tmp/angle/summary-%s' % model_id, sess.graph)\n",
    "\n",
    "#init or load from checkpoint\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "if load_dnn:\n",
    "    saver.restore(sess, 'tmp/angle/model/angle-%s-%s' % (model_id,step_counter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert label class to angle floats\n",
    "def convert_to_angle(y_data):\n",
    "    new_y = []\n",
    "    for y in y_data:\n",
    "        new_y.append(as_angle[labels[y]])\n",
    "    return new_y\n",
    "\n",
    "def test_all():\n",
    "    xtest,ytest,_ = samples.get_all(use_labels_data=False)\n",
    "    ytest = convert_to_angle(ytest)\n",
    "    val = sess.run(loss, feed_dict={x: xtest, y: ytest})\n",
    "    print(\"Loss: %s\" % val)\n",
    "    \n",
    "def test():\n",
    "    xtest,ytest,_ = samples.get_test(use_labels_data=False)\n",
    "    ytest = convert_to_angle(ytest)\n",
    "    val = sess.run(loss, feed_dict={x: xtest, y: ytest})\n",
    "    print(\"Loss: %s\" % val)\n",
    "\n",
    "def train(steps, batch_size):\n",
    "    global step_counter\n",
    "    progress = 5\n",
    "    for i in range(steps):\n",
    "        xtrain,ytrain,_ = samples.get_batch(batch_size, use_labels_data=False)\n",
    "        ytrain = convert_to_angle(ytrain)\n",
    "        summary,_ = sess.run([merged, optimizer], feed_dict={x: xtrain, y: ytrain})\n",
    "        train_writer.add_summary(summary, i+step_counter)\n",
    "        if i>=progress/100.0*steps-1:\n",
    "            print(\"Progress: %s%%\" % progress)\n",
    "            progress += 5\n",
    "            test()\n",
    "            saver.save(sess, 'tmp/angle/model/angle-%s' % (model_id), global_step=step_counter)\n",
    "    step_counter += steps\n",
    "    saver.save(sess, 'tmp/angle/model/angle-%s' % (model_id), global_step=step_counter)\n",
    "    \n",
    "def predict(x_input):\n",
    "    return sess.run(dnn_angle, feed_dict={x:x_input})\n",
    "\n",
    "def per_label_check():\n",
    "    xtest,ytest,_ = samples.get_test(use_labels_data=False)\n",
    "    ytest = convert_to_angle(ytest)\n",
    "    pred = predict(xtest)\n",
    "    print('Should - Is - Diff (abs)')\n",
    "    for i in range(len(ytest)):\n",
    "        print('%s - %s - %s' % (ytest[i], pred[i][0], abs(ytest[i]-pred[i][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 5%\n",
      "Loss: 0.331021\n",
      "Progress: 10%\n",
      "Loss: 0.331021\n",
      "Progress: 15%\n",
      "Loss: 0.331021\n",
      "Progress: 20%\n",
      "Loss: 0.331021\n",
      "Progress: 25%\n",
      "Loss: 0.331021\n",
      "Progress: 30%\n",
      "Loss: 0.331021\n",
      "Progress: 35%\n",
      "Loss: 0.331021\n",
      "Progress: 40%\n",
      "Loss: 0.331021\n",
      "Progress: 45%\n",
      "Loss: 0.331021\n",
      "Progress: 50%\n",
      "Loss: 0.331021\n",
      "Progress: 55%\n",
      "Loss: 0.331021\n",
      "Progress: 60%\n",
      "Loss: 0.331021\n",
      "Progress: 65%\n",
      "Loss: 0.331021\n",
      "Progress: 70%\n",
      "Loss: 0.331021\n",
      "Progress: 75%\n",
      "Loss: 0.331021\n",
      "Progress: 80%\n",
      "Loss: 0.331021\n",
      "Progress: 85%\n",
      "Loss: 0.331021\n",
      "Progress: 90%\n",
      "Loss: 0.331021\n",
      "Progress: 95%\n",
      "Loss: 0.331021\n",
      "Progress: 100%\n",
      "Loss: 0.331021\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    train(10000,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.331019\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    test_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Should - Is - Diff (abs)\n",
      "0.0 - 0.0836212 - 0.0836211889982\n",
      "0.0 - 0.0835618 - 0.0835617631674\n",
      "0.0 - 0.0838274 - 0.0838273540139\n",
      "0.0 - 0.0836359 - 0.0836359411478\n",
      "0.0 - 0.0836239 - 0.083623893559\n",
      "0.0 - 0.0836574 - 0.0836573764682\n",
      "0.0 - 0.0836101 - 0.083610124886\n",
      "0.0 - 0.0834851 - 0.0834850743413\n",
      "0.0 - 0.0811718 - 0.0811718478799\n",
      "0.0 - 0.0838336 - 0.0838335826993\n",
      "0.0 - 0.0836637 - 0.0836637318134\n",
      "0.0 - 0.0836321 - 0.0836321413517\n",
      "-0.6666666666666666 - 0.0832308 - 0.749897467593\n",
      "-0.6666666666666666 - 0.0837188 - 0.75038545082\n",
      "-0.6666666666666666 - 0.0827837 - 0.749450410406\n",
      "-0.6666666666666666 - 0.0818311 - 0.748497779171\n",
      "-0.6666666666666666 - 0.0833863 - 0.750052976112\n",
      "-0.6666666666666666 - 0.083779 - 0.750445658962\n",
      "-0.6666666666666666 - 0.0830101 - 0.749676751594\n",
      "-0.6666666666666666 - 0.0831596 - 0.749826217691\n",
      "-0.6666666666666666 - 0.0830606 - 0.749727251629\n",
      "-0.6666666666666666 - 0.0827033 - 0.749369921784\n",
      "-0.6666666666666666 - 0.080551 - 0.747217627863\n",
      "-0.6666666666666666 - 0.0839859 - 0.750652606289\n",
      "-0.3333333333333333 - 0.0849252 - 0.418258508046\n",
      "-0.3333333333333333 - 0.0834774 - 0.416810748478\n",
      "-0.3333333333333333 - 0.0831315 - 0.416464795669\n",
      "-0.3333333333333333 - 0.0833175 - 0.416650821765\n",
      "-0.3333333333333333 - 0.0818581 - 0.415191402038\n",
      "-0.3333333333333333 - 0.0834716 - 0.416804944475\n",
      "-0.3333333333333333 - 0.0835014 - 0.416834687193\n",
      "-0.3333333333333333 - 0.0829417 - 0.416275021931\n",
      "-0.3333333333333333 - 0.0819623 - 0.415295643111\n",
      "-0.3333333333333333 - 0.083671 - 0.417004284759\n",
      "-0.3333333333333333 - 0.0834264 - 0.416759726902\n",
      "-0.3333333333333333 - 0.0819339 - 0.4152672713\n",
      "0.5 - 0.0833693 - 0.416630730033\n",
      "0.5 - 0.0828959 - 0.417104057968\n",
      "0.5 - 0.083656 - 0.416343979537\n",
      "0.5 - 0.0831651 - 0.416834928095\n",
      "0.5 - 0.0836256 - 0.416374385357\n",
      "0.5 - 0.0772149 - 0.422785118222\n",
      "0.5 - 0.0836283 - 0.416371665895\n",
      "0.5 - 0.0837246 - 0.416275411844\n",
      "0.5 - 0.0845369 - 0.415463097394\n",
      "0.5 - 0.0836817 - 0.41631834954\n",
      "0.5 - 0.0836875 - 0.416312463582\n",
      "0.5 - 0.0831366 - 0.416863448918\n",
      "-0.5 - 0.0831622 - 0.583162233233\n",
      "-0.5 - 0.0835853 - 0.58358528465\n",
      "-0.5 - 0.0815405 - 0.581540450454\n",
      "-0.5 - 0.0826332 - 0.582633249462\n",
      "-0.5 - 0.0823749 - 0.582374900579\n",
      "-0.5 - 0.0836063 - 0.583606310189\n",
      "-0.5 - 0.0833059 - 0.58330591023\n",
      "-0.5 - 0.0819024 - 0.581902399659\n",
      "-0.5 - 0.0834976 - 0.58349762857\n",
      "-0.5 - 0.083673 - 0.583673015237\n",
      "-0.5 - 0.0828843 - 0.582884326577\n",
      "-0.5 - 0.0835944 - 0.583594411612\n",
      "0.6666666666666666 - 0.0850051 - 0.581661524872\n",
      "0.6666666666666666 - 0.0849964 - 0.581670234601\n",
      "0.6666666666666666 - 0.0824841 - 0.584182577829\n",
      "0.6666666666666666 - 0.0835626 - 0.583104046683\n",
      "0.6666666666666666 - 0.0815718 - 0.585094916324\n",
      "0.6666666666666666 - 0.0834367 - 0.583230013649\n",
      "0.6666666666666666 - 0.083469 - 0.583197648327\n",
      "0.6666666666666666 - 0.083222 - 0.583444657425\n",
      "0.6666666666666666 - 0.0827707 - 0.583895968894\n",
      "0.6666666666666666 - 0.0831643 - 0.58350233982\n",
      "0.6666666666666666 - 0.0834931 - 0.583173545698\n",
      "0.6666666666666666 - 0.0832428 - 0.583423825602\n",
      "1.0 - 0.0855659 - 0.914434097707\n",
      "1.0 - 0.0838585 - 0.916141502559\n",
      "1.0 - 0.083555 - 0.916444957256\n",
      "1.0 - 0.0824169 - 0.917583055794\n",
      "1.0 - 0.0835834 - 0.916416630149\n",
      "1.0 - 0.0837774 - 0.916222646832\n",
      "1.0 - 0.0839233 - 0.916076719761\n",
      "1.0 - 0.0835244 - 0.916475601494\n",
      "1.0 - 0.0836321 - 0.916367933154\n",
      "1.0 - 0.0826478 - 0.917352214456\n",
      "1.0 - 0.0820766 - 0.917923435569\n",
      "1.0 - 0.0823326 - 0.917667381465\n",
      "-0.8333333333333334 - 0.0841547 - 0.917487998803\n",
      "-0.8333333333333334 - 0.0830003 - 0.916333635648\n",
      "-0.8333333333333334 - 0.0837615 - 0.917094794412\n",
      "-0.8333333333333334 - 0.0827518 - 0.916085128983\n",
      "-0.8333333333333334 - 0.0854194 - 0.91875274231\n",
      "-0.8333333333333334 - 0.0837101 - 0.917043392857\n",
      "-0.8333333333333334 - 0.0836907 - 0.917024028798\n",
      "-0.8333333333333334 - 0.099387 - 0.932720315953\n",
      "-0.8333333333333334 - 0.0829357 - 0.916269001861\n",
      "-0.8333333333333334 - 0.083658 - 0.916991298397\n",
      "-0.8333333333333334 - 0.0817177 - 0.915051010748\n",
      "-0.8333333333333334 - 0.0821116 - 0.915444885691\n",
      "-0.16666666666666666 - 0.0810023 - 0.247668931882\n",
      "-0.16666666666666666 - 0.0837962 - 0.250462914507\n",
      "-0.16666666666666666 - 0.0835866 - 0.250253262619\n",
      "-0.16666666666666666 - 0.0835729 - 0.2502395461\n",
      "-0.16666666666666666 - 0.0822984 - 0.248965064685\n",
      "-0.16666666666666666 - 0.0822437 - 0.248910392324\n",
      "-0.16666666666666666 - 0.0830863 - 0.249753015737\n",
      "-0.16666666666666666 - 0.0816907 - 0.248357335726\n",
      "-0.16666666666666666 - 0.0830022 - 0.249668816725\n",
      "-0.16666666666666666 - 0.0832627 - 0.24992937843\n",
      "-0.16666666666666666 - 0.0836442 - 0.250310900311\n",
      "-0.16666666666666666 - 0.0835972 - 0.250263842444\n",
      "0.3333333333333333 - 0.0831774 - 0.250155967971\n",
      "0.3333333333333333 - 0.0838641 - 0.249469218155\n",
      "0.3333333333333333 - 0.0825683 - 0.250765082737\n",
      "0.3333333333333333 - 0.0846117 - 0.248721626898\n",
      "0.3333333333333333 - 0.0837533 - 0.24958003064\n",
      "0.3333333333333333 - 0.0836736 - 0.249659766754\n",
      "0.3333333333333333 - 0.0831482 - 0.250185107191\n",
      "0.3333333333333333 - 0.0836278 - 0.249705543121\n",
      "0.3333333333333333 - 0.0822631 - 0.251070228716\n",
      "0.3333333333333333 - 0.0835489 - 0.249784400066\n",
      "0.3333333333333333 - 0.0838731 - 0.249460240205\n",
      "0.3333333333333333 - 0.0832787 - 0.250054640075\n",
      "0.16666666666666666 - 0.0833246 - 0.0833420927326\n",
      "0.16666666666666666 - 0.0837642 - 0.0829024190704\n",
      "0.16666666666666666 - 0.081806 - 0.084860632817\n",
      "0.16666666666666666 - 0.0836366 - 0.0830301071207\n",
      "0.16666666666666666 - 0.0839125 - 0.08275419722\n",
      "0.16666666666666666 - 0.0836961 - 0.0829705397288\n",
      "0.16666666666666666 - 0.0836276 - 0.0830390850703\n",
      "0.16666666666666666 - 0.0838607 - 0.0828059564034\n",
      "0.16666666666666666 - 0.0832263 - 0.0834403435389\n",
      "0.16666666666666666 - 0.0836471 - 0.083019601802\n",
      "0.16666666666666666 - 0.0827364 - 0.0839302639167\n",
      "0.16666666666666666 - 0.0838493 - 0.0828173706929\n",
      "0.8333333333333334 - 0.0837411 - 0.749592264493\n",
      "0.8333333333333334 - 0.0837571 - 0.749576208492\n",
      "0.8333333333333334 - 0.08618 - 0.747153316935\n",
      "0.8333333333333334 - 0.0829656 - 0.750367743274\n",
      "0.8333333333333334 - 0.0818006 - 0.751532701155\n",
      "0.8333333333333334 - 0.0822492 - 0.751084116598\n",
      "0.8333333333333334 - 0.0837928 - 0.749540579816\n",
      "0.8333333333333334 - 0.083746 - 0.749587309857\n",
      "0.8333333333333334 - 0.0844511 - 0.74888219436\n",
      "0.8333333333333334 - 0.0835534 - 0.749779952069\n",
      "0.8333333333333334 - 0.0837642 - 0.749569108089\n",
      "0.8333333333333334 - 0.083884 - 0.749449310203\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    per_label_check()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
