{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import samples as ls\n",
    "import math\n",
    "\n",
    "\n",
    "#number of dimensions used and steps when unrolling\n",
    "input_dim = 6\n",
    "input_steps = 5\n",
    "\n",
    "hidden_layers = [50,10]\n",
    "\n",
    "#straight has to be number 0!\n",
    "labels = ['straight','curve_m','wall','object']\n",
    "classes = len(labels)\n",
    "\n",
    "#percentage used for test data\n",
    "test_rate = 0.1\n",
    "\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = ls.Samples(labels)\n",
    "\n",
    "for label in labels:\n",
    "    samples.load_samples(label = label)\n",
    "    \n",
    "samples.convert_to_input(size = 20)\n",
    "samples.unroll(input_steps)\n",
    "samples.split_test(test_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, input_steps, input_dim])\n",
    "y = tf.placeholder(tf.float32, [None, classes])\n",
    "\n",
    "Ws = []\n",
    "for i in range(len(hidden_layers)-1):\n",
    "    W = tf.Variable(tf.random_normal([hidden_layers[i], hidden_layers[i+1]]))\n",
    "    b = tf.Variable(tf.zeros(hidden_layers[i+1]))\n",
    "    Ws.append((W,b))\n",
    "W = tf.Variable(tf.random_normal([hidden_layers[-1], classes]))\n",
    "b = tf.Variable(tf.zeros([classes]))\n",
    "Ws.append((W,b))\n",
    "\n",
    "#x = [tf.placeholder(tf.float32, [None, input_dim]) for _ in range(input_steps)]\n",
    "#y = tf.placeholder(tf.float32, [None, classes])\n",
    "x2 = tf.unstack(x, input_steps, 1)\n",
    "\n",
    "#rnn_cell = tf.contrib.rnn.BasicRNNCell(hidden_layer)\n",
    "rnn_cell = tf.contrib.rnn.BasicLSTMCell(hidden_layers[0], forget_bias=1.0)\n",
    "outputs, state = tf.contrib.rnn.static_rnn(rnn_cell, x2, dtype=tf.float32)\n",
    "#outputs, state = tf.nn.dynamic_rnn(rnn_cell, x, dtype=tf.float32)\n",
    "#rnn = tf.matmul(outputs[-1],Ws[0][0]) + bs[0][0]\n",
    "\n",
    "preactivations = []\n",
    "activations = []\n",
    "act = outputs[-1]\n",
    "for W,b in Ws:\n",
    "    preact = tf.matmul(act, W) + b\n",
    "    preactivations.append(preact)\n",
    "    act = tf.nn.relu(preact)\n",
    "    #act = tf.sigmoid(preact)\n",
    "    activations.append(act)\n",
    "rnn = tf.nn.softmax(preact)\n",
    "activations[-1] = rnn\n",
    "rnn_pred = tf.argmax(rnn, 1, name='RNN_pred')\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=rnn))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)\n",
    "#optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), rnn_pred)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "#summaries\n",
    "def var_summary(var, name):\n",
    "    mean = tf.reduce_mean(var)\n",
    "    tf.summary.scalar(name + '_mean', mean)\n",
    "    stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "    tf.summary.scalar(name + '_stddev', stddev)\n",
    "    tf.summary.scalar(name + '_max', tf.reduce_max(var))\n",
    "    tf.summary.scalar(name + '_min', tf.reduce_min(var))\n",
    "    tf.summary.histogram(name + '_histogram', var)\n",
    "i = 0\n",
    "for W,b in Ws: \n",
    "    var_summary(W, 'weights_%s' % i)\n",
    "    var_summary(b, 'bias_%s' % i)\n",
    "    i += 1\n",
    "for i in range(len(activations)):\n",
    "    tf.summary.histogram('preactivations_%s' % i, preactivations[i])\n",
    "    tf.summary.histogram('activations_%s' % i, activations[i])\n",
    "tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "step_counter = 0\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter('tmp/rnn/summary', sess.graph)\n",
    "\n",
    "#init or load from checkpoint\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "#saver.restore(sess, 'tmp/rnn/model/rnn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_onehot(labels):\n",
    "    new_labels = []\n",
    "    for y in labels:\n",
    "        label = [0]*classes\n",
    "        label[y] = 1\n",
    "        new_labels.append(label)\n",
    "    return new_labels\n",
    "\n",
    "def test_all():\n",
    "    xtest,ytest = samples.get_all()\n",
    "    xtest = np.array(xtest)\n",
    "    ytest = np.array(convert_to_onehot(ytest))\n",
    "    acc = sess.run(accuracy, feed_dict={x: xtest, y: ytest})\n",
    "    print(\"Accuracy: %s\" % acc)\n",
    "    \n",
    "def test():\n",
    "    xtest,ytest = samples.get_test()\n",
    "    xtest = np.array(xtest)\n",
    "    ytest = np.array(convert_to_onehot(ytest))\n",
    "    acc = sess.run(accuracy, feed_dict={x: xtest, y: ytest})\n",
    "    print(\"Accuracy: %s\" % acc)\n",
    "\n",
    "def train(steps, batch_size):\n",
    "    global step_counter\n",
    "    progress = 5\n",
    "    for i in range(steps):\n",
    "        xtrain,ytrain = samples.get_batch(batch_size)\n",
    "        xtrain = np.array(xtrain)\n",
    "        ytrain = np.array(convert_to_onehot(ytrain))\n",
    "        summary,_ = sess.run([merged, optimizer], feed_dict={x: xtrain, y:ytrain})\n",
    "        train_writer.add_summary(summary, i+step_counter)\n",
    "        if i>=progress/100.0*steps-1:\n",
    "            print(\"Progress: %s%%\" % progress)\n",
    "            progress += 5\n",
    "            test()\n",
    "            saver.save(sess, 'tmp/rnn/model/rnn', global_step=step_counter)\n",
    "    step_counter += steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(10000,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feed_data(data):\n",
    "    if len(data) < input_steps: raise ValueError('Data too short')\n",
    "    results = []\n",
    "    for i in range(len(data) - input_steps + 1):\n",
    "        batch = np.array(data[:input_steps])\n",
    "        res = sess.run(rnn_pred, feed_dict={x:[batch]})\n",
    "        results.append([list(res), list(batch)])\n",
    "        data.pop(0)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prove of memory\n",
    "a = [0,0,0,0,0,0]\n",
    "b = [0,2,0,5,-100,0]\n",
    "res_t = []\n",
    "for i in range(109):\n",
    "    data1 = [b,b,b,b,b,a,a,a,a,a,a,a,a,a,a,a]\n",
    "    res = feed_data(data1)\n",
    "    te = []\n",
    "    for r in res:\n",
    "        te.append(r[0])\n",
    "    res_t.append(te)\n",
    "print(res_t[1:] == res_t[:-1])\n",
    "print(res_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
