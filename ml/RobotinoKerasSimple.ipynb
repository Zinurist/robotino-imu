{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model parameters\n",
    "import numpy as np\n",
    "import samples as ls\n",
    "import math\n",
    "import model_types\n",
    "\n",
    "\n",
    "# networks used for thesis:\n",
    "# RNNs:\n",
    "# 0/1/2_9\n",
    "# 10/11_34, 12_36 (34 used sgd, 36 adam, not really a difference)\n",
    "# DNNs:\n",
    "# 11_39 (sigmoid)\n",
    "# 11_45 (relu)\n",
    "\n",
    "# quick overview of the modes:\n",
    "# 1. load_test: Load the test data for final evaluation. It is only used for testing and not training\n",
    "# 2. predict_mode: No training. Load all data uncut/without unrolling. \n",
    "#                  Makes recurrent networks stateful (they remember their state between runs). This enables the live demo.\n",
    "# 3. None of the above: Training mode, used to train the networks.\n",
    "\n",
    "\n",
    "#--------- TRAINING MODES --------------\n",
    "#load final test data for final evaluation\n",
    "load_test = False\n",
    "\n",
    "#enable to make RNNs stateful (save state between batches) and to not unroll training data for whole sample comparison\n",
    "predict_mode = True\n",
    "\n",
    "#load the network from saved file (needs to be False if network is not yet created)\n",
    "load_rnn = True if not predict_mode else False\n",
    "#only load the weights, not the architecture\n",
    "load_only_weights = False if not load_rnn else False\n",
    "#model to use (num=architecture, type=labels/task)\n",
    "model_num = 9\n",
    "model_type = 2\n",
    "\n",
    "train_network = False if not load_test else False\n",
    "live_demo = False\n",
    "\n",
    "\n",
    "#--------- MODEL DATA --------------\n",
    "model_id = '%s_%s' % (model_type, model_num)\n",
    "model_path = 'tmp/keras/nn-%s.hdf5' % model_id\n",
    "weights_path = 'tmp/keras/nn-%s_weights.hdf5' % model_id\n",
    "labels,sample_ids,filename = model_types.get_labels(model_type, load_test)\n",
    "\n",
    "\n",
    "#--------- MODEL HYPERPARAMETERS --------------\n",
    "accel,gyro,compass = 'xyz','xyz',''\n",
    "overlap_step = 1\n",
    "use_labels_data = False #-> if true, output at each timestep is compared (should be true for first two tasks)\n",
    "use_lstm = True\n",
    "use_sgd = False #-> if false, adamoptimizer is used\n",
    "use_rnn = True #use a recurrent cell\n",
    "input_steps = 50 #both set to 50 as the default setting for the angle network\n",
    "unroll_steps = 50\n",
    "activation = 'sigmoid'\n",
    "load_samples = True\n",
    "dropout_prob = 0 #for recurrent cells\n",
    "dropout_dense = False #for dense layers\n",
    "complete_unroll = False\n",
    "\n",
    "\n",
    "#--------- MODEL DEFINITIONS --------------\n",
    "elif model_num == 9:\n",
    "    input_steps = None\n",
    "    unroll_steps = 100\n",
    "    overlap_step = 50\n",
    "    use_labels_data = True\n",
    "    complete_unroll = True\n",
    "    hidden_layers = [14]\n",
    "elif model_num == 34:\n",
    "    use_rnn = True\n",
    "    use_lstm = True\n",
    "    use_labels_data = False\n",
    "    load_samples = False\n",
    "    use_sgd = True\n",
    "    hidden_layers = [24]\n",
    "elif model_num == 36:\n",
    "    use_rnn = True\n",
    "    use_lstm = True\n",
    "    use_labels_data = False\n",
    "    load_samples = False\n",
    "    hidden_layers = [24]\n",
    "elif model_num == 39:\n",
    "    use_rnn = False\n",
    "    activation = 'sigmoid'\n",
    "    hidden_layers = [50,24]\n",
    "elif model_num == 45:\n",
    "    use_rnn = False\n",
    "    activation = 'relu'\n",
    "    hidden_layers = [24,24,24,24,12]\n",
    "else:\n",
    "    raise ValueError('Unknown model')\n",
    "    \n",
    "classes = len(labels)\n",
    "\n",
    "#predict mode/test mode -> dont unroll for task 1 and 2\n",
    "if predict_mode:\n",
    "    input_steps = None\n",
    "    unroll_steps = None\n",
    "    overlap_step = 1\n",
    "#however, for angle task always unroll\n",
    "if model_type >= 10: \n",
    "    load_samples = False\n",
    "    input_steps = 50 #both set to 50 as the default setting for the angle network\n",
    "    unroll_steps = 50\n",
    "\n",
    "#percentage used for validation data\n",
    "test_rate = 0.1 if not load_test else 1\n",
    "\n",
    "#learning rate for sgd if used\n",
    "learning_rate = 0.01\n",
    "\n",
    "print('model: %s (type %s, num %s)' % (model_id,model_type,model_num))\n",
    "print('%s classes' % (classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------- PREPARE DATA --------------\n",
    "#load samples\n",
    "if load_samples:\n",
    "    samples = ls.load(filename)\n",
    "else:\n",
    "    samples = ls.Samples(labels)\n",
    "    \n",
    "    for label in labels:\n",
    "        samples.load_samples(label = label, sample_ids = sample_ids)\n",
    "\n",
    "    samples.convert_to_input(size = None, accel=accel, gyro=gyro, compass=compass)\n",
    "\n",
    "samples.unroll(unroll_steps, overlap_step, complete=complete_unroll)\n",
    "samples.convert_to_onehot()\n",
    "samples.split_test(test_rate, random=False)\n",
    "if not use_rnn: samples.flatten()\n",
    "\n",
    "input_dim = samples.input_dim\n",
    "print(\"dim: %s\" % input_dim)\n",
    "    \n",
    "#prepare training data\n",
    "xtrain,ytrain,seqlen = samples.get_all(padding=False, use_labels_data=use_labels_data)\n",
    "xtest,ytest,seqlentest = samples.get_test(padding=False, use_labels_data=use_labels_data)\n",
    "\n",
    "if unroll_steps is None and not predict_mode and not load_test:\n",
    "    from keras.preprocessing import sequence\n",
    "    xtrain = sequence.pad_sequences(xtrain)\n",
    "    xtest = sequence.pad_sequences(xtest)\n",
    "    #not efficient but whatevs\n",
    "    if len(xtrain[0]) > len(xtest[0]):\n",
    "        input_steps = len(xtrain[0])\n",
    "        xtest = sequence.pad_sequences(xtest, maxlen=input_steps)\n",
    "    elif len(xtrain[0]) < len(xtest[0]):\n",
    "        input_steps = len(xtest[0])\n",
    "        xtrain = sequence.pad_sequences(xtrain, maxlen=input_steps)\n",
    "    else:\n",
    "        input_steps = len(xtrain[0])\n",
    "    \n",
    "    ytrain = sequence.pad_sequences(ytrain, maxlen=input_steps)\n",
    "    ytest = sequence.pad_sequences(ytest, maxlen=input_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------- PREPARE MODELS --------------\n",
    "#create/load model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout\n",
    "from keras.layers import LSTM, SimpleRNN\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.core import Masking\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "if load_rnn and not load_only_weights:\n",
    "    model = load_model(model_path)\n",
    "    model.load_weights(weights_path)\n",
    "else:\n",
    "    model = Sequential()\n",
    "    if unroll_steps is None and not predict_mode:\n",
    "        #variable length -> mask paddings\n",
    "        #(not implemented for predict_mode)\n",
    "        model.add(Masking(input_shape=(input_steps, input_dim)))\n",
    "        \n",
    "        if use_lstm:\n",
    "            model.add(LSTM(hidden_layers.pop(0), dropout=dropout_prob, recurrent_dropout=dropout_prob, \n",
    "                       return_sequences=use_labels_data))\n",
    "        else:\n",
    "            model.add(SimpleRNN(hidden_layers.pop(0), dropout=dropout_prob, recurrent_dropout=dropout_prob, \n",
    "                       return_sequences=use_labels_data))\n",
    "                     \n",
    "        if use_labels_data:\n",
    "            for k in hidden_layers:\n",
    "                model.add(TimeDistributed(Dense(k, activation=activation)))\n",
    "            model.add(TimeDistributed(Dense(classes, activation='softmax')))\n",
    "        else:\n",
    "            for k in hidden_layers:\n",
    "                model.add(Dense(k, activation=activation))\n",
    "            model.add(Dense(classes, activation='softmax'))\n",
    "        \n",
    "    elif use_rnn:\n",
    "        #recurrent structure: one recurrent cell followed by time distributed layers\n",
    "        if use_lstm:\n",
    "            if predict_mode:\n",
    "                model.add(LSTM(hidden_layers.pop(0), dropout=dropout_prob, recurrent_dropout=dropout_prob, \n",
    "                       batch_input_shape=(1, input_steps, input_dim), return_sequences=use_labels_data, stateful=True))\n",
    "            else:\n",
    "                #hidden_layers.append(classes)\n",
    "                #model.add(LSTM(hidden_layers.pop(0), activation='softmax', dropout=dropout_prob, recurrent_dropout=dropout_prob, \n",
    "                #       input_shape=(input_steps, input_dim), return_sequences=use_labels_data))\n",
    "                model.add(LSTM(hidden_layers.pop(0), dropout=dropout_prob, recurrent_dropout=dropout_prob, \n",
    "                       input_shape=(input_steps, input_dim), return_sequences=use_labels_data))\n",
    "        else:\n",
    "            if predict_mode:\n",
    "                model.add(SimpleRNN(hidden_layers.pop(0), dropout=dropout_prob, recurrent_dropout=dropout_prob, \n",
    "                       batch_input_shape=(1, input_steps, input_dim), return_sequences=use_labels_data, stateful=True))\n",
    "            else:\n",
    "                model.add(SimpleRNN(hidden_layers.pop(0), dropout=dropout_prob, recurrent_dropout=dropout_prob, \n",
    "                       input_shape=(input_steps, input_dim), return_sequences=use_labels_data))\n",
    "                     \n",
    "        if use_labels_data:\n",
    "            for k in hidden_layers:\n",
    "                model.add(TimeDistributed(Dense(k, activation=activation)))\n",
    "            model.add(TimeDistributed(Dense(classes, activation='softmax')))\n",
    "        else:\n",
    "            for k in hidden_layers:\n",
    "                model.add(Dense(k, activation=activation))\n",
    "            model.add(Dense(classes, activation='softmax'))\n",
    "    else:\n",
    "        #purely DNN\n",
    "        if not hidden_layers: #(no hidden layers)\n",
    "            model.add(Dense(classes, activation='softmax', input_shape=(input_steps*input_dim,)))\n",
    "        else:\n",
    "            model.add(Dense(hidden_layers.pop(0), activation=activation, input_shape=(input_steps*input_dim,)))\n",
    "            for k in hidden_layers:\n",
    "                model.add(Dense(k, activation=activation))\n",
    "                if dropout_dense: model.add(Dropout(0.2))\n",
    "            model.add(Dense(classes, activation='softmax'))\n",
    "   \n",
    "        \n",
    "    \n",
    "\n",
    "    if use_sgd: opt = optimizers.SGD(lr=learning_rate)\n",
    "    else: opt = 'adam'\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    if predict_mode or load_only_weights:\n",
    "        #do not save model in predict_mode!\n",
    "        model.load_weights(weights_path)\n",
    "    else:\n",
    "        model.save(model_path)\n",
    "        model.save_weights(weights_path)\n",
    "        \n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--------- TRAINING/PREDICTION FUNCTIONS --------------\n",
    "if not predict_mode:\n",
    "    #only relevant when training, not in predict mode\n",
    "    \"\"\"\n",
    "    Trains the network for the given epochs and batch_size. The network with the best validation accuracy is saved.\n",
    "    @param epochs: how many epochs to train for\n",
    "    @param batch_size: the batch size to use\n",
    "    \"\"\"\n",
    "    def train(epochs, batch_size):\n",
    "        mcp = ModelCheckpoint(weights_path, monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
    "        model.fit(xtrain, ytrain,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  validation_data=(xtest, ytest),\n",
    "                  callbacks=[mcp])\n",
    "        score, acc = model.evaluate(xtest, ytest, batch_size=len(xtest))\n",
    "        print('Test score: %s' % score)\n",
    "        print('Test accuracy: %s' % acc)\n",
    "        #model.save(model_path)\n",
    "        #model.save_weights(weights_path)\n",
    "        \n",
    "\"\"\"\n",
    "Test all available data (both train and validation set).\n",
    "@param batch_size: feed batches of this size to reduce memory needed\n",
    "\"\"\"    \n",
    "def test_total(batch_size=None):\n",
    "    if batch_size == None:\n",
    "        acc1 = model.evaluate(xtrain, ytrain, batch_size=len(xtrain), verbose=0)[1]\n",
    "        acc2 = model.evaluate(xtest, ytest, batch_size=len(xtest), verbose=0)[1]\n",
    "    else:\n",
    "        acc1 = 0\n",
    "        num = len(xtrain)\n",
    "        for i in range(0,num,batch_size):\n",
    "            size = min(batch_size, len(xtrain)-i)\n",
    "            xtrain2 = xtrain[i:i+size]\n",
    "            ytrain2 = ytrain[i:i+size]\n",
    "            acc1 += (float(size)/num) * model.evaluate(xtrain2, ytrain2, batch_size=size, verbose=0)[1]\n",
    "\n",
    "        acc2 = 0\n",
    "        num = len(xtest)\n",
    "        for i in range(0,num,batch_size):\n",
    "            size = min(batch_size, len(xtest)-i)\n",
    "            xtrain2 = xtest[i:i+size]\n",
    "            ytrain2 = ytest[i:i+size]\n",
    "            acc2 += (float(size)/num) * model.evaluate(xtrain2, ytrain2, batch_size=size, verbose=0)[1]\n",
    "    acc = acc1*(1.0-test_rate) + acc2*test_rate\n",
    "    print('Train accuracy: %s' % acc1)\n",
    "    print('Test accuracy: %s' % acc2)\n",
    "    print('Total accuracy: %s' % acc)\n",
    "\n",
    "\"\"\"\n",
    "Evaluate the model using the test/validation data.\n",
    "\"\"\"\n",
    "def test():\n",
    "    score, acc = model.evaluate(xtest, ytest, batch_size=len(xtest))\n",
    "    print('Test score: %s' % score)\n",
    "    print('Test accuracy: %s' % acc)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Calculates the per-label accuracies.\n",
    "@param test: if true, the test/validation set is used\n",
    "\"\"\"\n",
    "def per_label_acc(test=True):\n",
    "    if test:\n",
    "        x,y = xtest,ytest\n",
    "    else:\n",
    "        x,y = xtrain,ytrain\n",
    "    accs = [0] * classes\n",
    "    counts = [0] * classes\n",
    "\n",
    "    print_step = len(y)/10\n",
    "    for i in range(len(y)):\n",
    "        acc = model.evaluate(np.array([x[i]]), np.array([y[i]]), batch_size=1, verbose=0)[1]\n",
    "        c = 0\n",
    "        if use_labels_data:\n",
    "            for y_oh in y[i]:\n",
    "                c = np.argmax(y_oh)\n",
    "                accs[c] += acc\n",
    "                counts[c] += 1\n",
    "        else:\n",
    "            c = np.argmax(y[i])\n",
    "            accs[c] += acc\n",
    "            counts[c] += 1\n",
    "        if i%print_step==0:\n",
    "            print('Progress: %s' % (float(i)/len(y)))\n",
    "\n",
    "    acc_total = 0\n",
    "    for i in range(classes):\n",
    "        acc = accs[i]/counts[i]\n",
    "        print('%sx %s: %s' % (counts[i],labels[i],acc))\n",
    "        acc_total += acc*1.0/classes\n",
    "    print('Total test acc: %s' % acc_total)\n",
    "\n",
    "\"\"\"\n",
    "Interface to make feeding data through a recurrent network simpler.\n",
    "@param s: list of data points, if feeding only a single timestep, this needs to be a list with one element\n",
    "@param as_prob: return the output as probabilities instead of argmax\n",
    "@return a list with the output of the network for each of the input steps\n",
    "\"\"\"\n",
    "def feed_seq(s, as_prob=False):\n",
    "    if normalize:\n",
    "        for step in s:\n",
    "            norm(step)\n",
    "    res = model.predict(np.array([s]),batch_size=1)[0]\n",
    "    resarg = []\n",
    "    for r in res:\n",
    "        if as_prob: resarg.append(r)\n",
    "        else: resarg.append(np.argmax(r))\n",
    "    return resarg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small test: compare output of network for one example sample (for each label)\n",
    "if predict_mode:\n",
    "    if False:\n",
    "        import time\n",
    "        start = time.time()\n",
    "        for i in range(10000):\n",
    "            z = [0,0,0,0,0,0]\n",
    "            v = [z]*1\n",
    "            feed_seq(v)\n",
    "        dt = time.time() - start\n",
    "        print('%s hz' % (1/(dt/10000)))\n",
    "\n",
    "    if True:\n",
    "        for key in samples.test:\n",
    "            model.reset_states()\n",
    "            xdata = samples.test[key][0][0]\n",
    "            ydata = samples.labels_test[key][0][0]\n",
    "\n",
    "            res = feed_seq(xdata)\n",
    "\n",
    "            res_predicted = res\n",
    "            res_expected = []\n",
    "            acc = 0\n",
    "            for i in range(len(res)):\n",
    "                res_expected.append(np.argmax(ydata[i]))\n",
    "                if res_predicted[len(res_expected)-1] == res_expected[-1]:\n",
    "                    acc += 1.0\n",
    "            print('%s: %s' % (key, acc/len(res)))\n",
    "            print(res_predicted)\n",
    "            print(res_expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display how many samples are available\n",
    "if True:\n",
    "    for key in labels:\n",
    "        print('%s: %s / %s' % (key, len(samples.data[key]), len(samples.test[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train the network\n",
    "if train_network and not predict_mode:\n",
    "    train(300,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate model\n",
    "if True:\n",
    "    per_label_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#live demo\n",
    "%env ROS_HOSTNAME=zinunb\n",
    "%env ROS_IP=$(hostname -I)\n",
    "%env ROS_MASTER_URI=http://pi:11311\n",
    "        \n",
    "if live_demo and predict_mode:\n",
    "    import imu_listener as il\n",
    "    #reset()\n",
    "    listener = il.imu_listener(feed_seq,labels,1,1,record=False)\n",
    "    #listener.save_history()\n",
    "    print('Exited')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
