{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model parameters\n",
    "import numpy as np\n",
    "import samples as ls\n",
    "import math\n",
    "import model_types\n",
    "\n",
    "\n",
    "# networks used for thesis:\n",
    "# RNNs:\n",
    "# 0/1/2_9\n",
    "# 10/11_34, 12_36 (34 used sgd, 36 adam, not really a difference)\n",
    "# DNNs:\n",
    "# 11_39 (sigmoid)\n",
    "# 11_45 (relu)\n",
    "\n",
    "# quick overview of the modes:\n",
    "# 1. load_test: Load the test data for final evaluation. It is only used for testing and not training\n",
    "# 2. predict_mode: No training. Load all data uncut/without unrolling. \n",
    "#                  Makes recurrent networks stateful (they remember their state between runs). This enables the live demo.\n",
    "# 3. None of the above: Training mode, used to train the networks.\n",
    "\n",
    "\n",
    "#--------- TRAINING MODES --------------\n",
    "#load final test data for final evaluation\n",
    "load_test = False\n",
    "\n",
    "#enable to make RNNs stateful (save state between batches) and to not unroll training data for whole sample comparison\n",
    "predict_mode = False\n",
    "\n",
    "#load the network from saved file (needs to be False if network is not yet created)\n",
    "load_rnn = True if not predict_mode else False\n",
    "#only load the weights, not the architecture\n",
    "load_only_weights = False if not load_rnn else False\n",
    "#model to use (num=architecture, type=labels/task)\n",
    "model_num = 34\n",
    "model_type = 11\n",
    "\n",
    "train_network = False if not load_test else False\n",
    "live_demo = False\n",
    "\n",
    "\n",
    "#--------- MODEL DATA --------------\n",
    "model_id = '%s_%s' % (model_type, model_num)\n",
    "model_path = 'tmp/keras/nn-%s.hdf5' % model_id\n",
    "weights_path = 'tmp/keras/nn-%s_weights.hdf5' % model_id\n",
    "labels,sample_ids,filename = model_types.get_labels(model_type, load_test)\n",
    "\n",
    "\n",
    "#--------- MODEL HYPERPARAMETERS --------------\n",
    "accel,gyro,compass = 'xyz','xyz',''\n",
    "overlap_step = 1\n",
    "use_labels_data = False #-> if true, output at each timestep is compared (should be true for first two tasks)\n",
    "use_lstm = True\n",
    "use_sgd = False #-> if false, adamoptimizer is used\n",
    "use_rnn = True #use a recurrent cell\n",
    "input_steps = 50 #both set to 50 as the default setting for the angle network\n",
    "unroll_steps = 50\n",
    "activation = 'sigmoid'\n",
    "load_samples = True\n",
    "dropout_prob = 0 #for recurrent cells\n",
    "dropout_dense = False #for dense layers\n",
    "complete_unroll = False\n",
    "add_absolutes = False\n",
    "add_moving_average = False\n",
    "normalize = False\n",
    "\n",
    "\n",
    "#--------- MODEL DEFINITIONS --------------\n",
    "if model_num == 0:\n",
    "    input_steps = None\n",
    "    unroll_steps = 100\n",
    "    overlap_step = 50\n",
    "    use_labels_data = True\n",
    "    use_sgd = True\n",
    "    hidden_layers = [50]\n",
    "elif model_num == 4:\n",
    "    input_steps = None\n",
    "    unroll_steps = 100\n",
    "    overlap_step = 50\n",
    "    use_labels_data = True\n",
    "    use_sgd = True\n",
    "    hidden_layers = [50]\n",
    "elif model_num == 6:\n",
    "    input_steps = None\n",
    "    unroll_steps = 100\n",
    "    overlap_step = 50\n",
    "    use_labels_data = True\n",
    "    hidden_layers = [10]\n",
    "elif model_num == 7:#trained with new data\n",
    "    input_steps = None\n",
    "    unroll_steps = 100\n",
    "    overlap_step = 50\n",
    "    use_labels_data = True\n",
    "    hidden_layers = [50]\n",
    "elif model_num == 8:\n",
    "    input_steps = None\n",
    "    unroll_steps = 100\n",
    "    overlap_step = 50\n",
    "    use_labels_data = True\n",
    "    complete_unroll = True\n",
    "    add_absolutes = True\n",
    "    add_moving_average = True\n",
    "    hidden_layers = [18*2]\n",
    "elif model_num == 9:\n",
    "    input_steps = None\n",
    "    unroll_steps = 100\n",
    "    overlap_step = 50\n",
    "    use_labels_data = True\n",
    "    complete_unroll = True\n",
    "    hidden_layers = [14]\n",
    "elif model_num == 10:#trained with normalized data\n",
    "    input_steps = None\n",
    "    unroll_steps = 100\n",
    "    overlap_step = 50\n",
    "    use_labels_data = True\n",
    "    complete_unroll = True\n",
    "    normalize = True\n",
    "    hidden_layers = [14]\n",
    "    \n",
    "    \n",
    "elif model_num ==15:\n",
    "    input_steps = None\n",
    "    unroll_steps = 100\n",
    "    overlap_step = 50\n",
    "    use_labels_data = True\n",
    "    hidden_layers = []\n",
    "elif model_num ==16:\n",
    "    input_steps = None\n",
    "    unroll_steps = 100\n",
    "    overlap_step = 50\n",
    "    use_labels_data = True\n",
    "    hidden_layers = [14]\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "elif model_num == 33:\n",
    "    use_rnn = True\n",
    "    use_lstm = True\n",
    "    use_labels_data = False\n",
    "    load_samples = False\n",
    "    use_sgd = True\n",
    "    add_absolutes = True\n",
    "    add_moving_average = True\n",
    "    hidden_layers = [24]\n",
    "\n",
    "elif model_num == 32:\n",
    "    use_rnn = True\n",
    "    use_lstm = True\n",
    "    use_labels_data = False\n",
    "    load_samples = False\n",
    "    use_sgd = True\n",
    "    add_absolutes = True\n",
    "    add_moving_average = True\n",
    "    hidden_layers = [18*2]\n",
    "\n",
    "elif model_num == 34:\n",
    "    use_rnn = True\n",
    "    use_lstm = True\n",
    "    use_labels_data = False\n",
    "    load_samples = False\n",
    "    use_sgd = True\n",
    "    hidden_layers = [24]\n",
    "elif model_num == 36:\n",
    "    use_rnn = True\n",
    "    use_lstm = True\n",
    "    use_labels_data = False\n",
    "    load_samples = False\n",
    "    hidden_layers = [24]\n",
    "    \n",
    "    \n",
    "elif model_num == 40:\n",
    "    use_rnn = False\n",
    "    activation = 'sigmoid'\n",
    "    hidden_layers = [50,50,50]\n",
    "elif model_num == 41:\n",
    "    use_rnn = False\n",
    "    activation = 'sigmoid'\n",
    "    hidden_layers = [50,24]\n",
    "elif model_num == 39:\n",
    "    use_rnn = False\n",
    "    activation = 'sigmoid'\n",
    "    hidden_layers = [50,24]\n",
    "elif model_num == 42:\n",
    "    use_rnn = False\n",
    "    hidden_layers = [24,24,12]\n",
    "elif model_num == 45:\n",
    "    use_rnn = False\n",
    "    activation = 'relu'\n",
    "    hidden_layers = [24,24,24,24,12]\n",
    "elif model_num == 46:\n",
    "    use_rnn = False\n",
    "    activation = 'relu'\n",
    "    hidden_layers = [24,24,24,24,24,12]\n",
    "elif model_num == 47:\n",
    "    use_rnn = False\n",
    "    activation = 'relu'\n",
    "    dropout_dense = True\n",
    "    hidden_layers = [24,24,24,24,24,12]\n",
    "elif model_num == 48:\n",
    "    use_rnn = False\n",
    "    activation = 'relu'\n",
    "    dropout_dense = True\n",
    "    hidden_layers = [48,24,24,24,24,24]\n",
    "else:\n",
    "    raise ValueError('Unknown model')\n",
    "\n",
    "    \n",
    "input_dim = len(accel)+len(gyro)+len(compass)\n",
    "\n",
    "classes = len(labels)\n",
    "\n",
    "#predict mode/test mode -> dont unroll for task 1 and 2\n",
    "if predict_mode:\n",
    "    input_steps = None\n",
    "    unroll_steps = None\n",
    "    overlap_step = 1\n",
    "#however, for angle task always unroll\n",
    "if model_type >= 10: \n",
    "    load_samples = False\n",
    "    input_steps = 50 #both set to 50 as the default setting for the angle network\n",
    "    unroll_steps = 50\n",
    "\n",
    "#percentage used for validation data\n",
    "test_rate = 0.1 if not load_test else 1\n",
    "\n",
    "#learning rate for sgd if used\n",
    "learning_rate = 0.01\n",
    "\n",
    "print('model: %s (type %s, num %s)' % (model_id,model_type,model_num))\n",
    "print('%s classes, input_dim %s' % (classes, input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------- PREPARE DATA --------------\n",
    "#load samples\n",
    "if load_samples:\n",
    "    samples = ls.load(filename)\n",
    "else:\n",
    "    samples = ls.Samples(labels)\n",
    "    \n",
    "    for label in labels:\n",
    "        samples.load_samples(label = label, sample_ids = sample_ids)\n",
    "\n",
    "    samples.convert_to_input(size = None, accel=accel, gyro=gyro, compass=compass)\n",
    "\n",
    "if add_absolutes:\n",
    "    samples.add_absolutes()\n",
    "    input_dim += len(accel)+len(gyro)+len(compass)\n",
    "if add_moving_average:\n",
    "    samples.add_moving_average()\n",
    "    input_dim += len(accel)+len(gyro)+len(compass)\n",
    "samples.unroll(unroll_steps, overlap_step, complete=complete_unroll)\n",
    "samples.convert_to_onehot()\n",
    "samples.split_test(test_rate, random=False)\n",
    "if not use_rnn: samples.flatten()\n",
    "    \n",
    "    \n",
    "#prepare training data\n",
    "xtrain,ytrain,seqlen = samples.get_all(padding=False, use_labels_data=use_labels_data)\n",
    "xtest,ytest,seqlentest = samples.get_test(padding=False, use_labels_data=use_labels_data)\n",
    "#xtest/ytest is the validation data (or the test data when having the test set loaded)\n",
    "\n",
    "\n",
    "#normalize data\n",
    "if normalize:\n",
    "    \n",
    "    mean = [0]*input_dim\n",
    "    maxx = [-100000]*input_dim\n",
    "    minx = [1000000]*input_dim\n",
    "    for dataset in [xtrain,xtest]:\n",
    "        for x in dataset:\n",
    "            for step in x:\n",
    "                for d in range(input_dim):\n",
    "                    mean[d] += step[d]\n",
    "                    if maxx[d] < step[d]: maxx[d] = step[d]\n",
    "                    if minx[d] > step[d]: minx[d] = step[d]\n",
    "\n",
    "    for d in range(input_dim):\n",
    "        #only for z axis\n",
    "        #mean[d] = mean[d]/(len(xtrain)*len(xtrain[0])+len(xtest)*len(xtest[0]))\n",
    "        mean[d] = 0 if d != 2 else 1\n",
    "        maxx[d] -= mean[d]\n",
    "        minx[d] -= mean[d]\n",
    "        \n",
    "    \n",
    "    def norm(x):\n",
    "        for d in range(input_dim):\n",
    "            x[d] -= mean[d]\n",
    "            x[d] = (x[d] - minx[d]) / (maxx[d] - minx[d])\n",
    "            x[d] = x[d]*2 - 1\n",
    "        \n",
    "    for dataset in [xtrain,xtest]:\n",
    "        for x in dataset:\n",
    "            for step in x:\n",
    "                norm(step)\n",
    "\n",
    "    print(mean)\n",
    "    print(maxx)\n",
    "    print(minx)\n",
    "    \n",
    "    #constants\n",
    "    mean = [0, 0, 1, 0, 0, 0]\n",
    "    maxx = [5.1043901443481445, 4.228890419006348, 0.26448965072631836, 0.49148064851760864, 0.2268102616071701, 0.6176088452339172]\n",
    "    minx = [-2.644476890563965, -18.73173713684082, -0.34867972135543823, -0.6155312657356262, -0.2226802408695221, -0.6029812693595886]\n",
    "\n",
    "\n",
    "\n",
    "if unroll_steps is None and not predict_mode and not load_test:\n",
    "    from keras.preprocessing import sequence\n",
    "    xtrain = sequence.pad_sequences(xtrain)\n",
    "    xtest = sequence.pad_sequences(xtest)\n",
    "    #not efficient but whatevs\n",
    "    if len(xtrain[0]) > len(xtest[0]):\n",
    "        input_steps = len(xtrain[0])\n",
    "        xtest = sequence.pad_sequences(xtest, maxlen=input_steps)\n",
    "    elif len(xtrain[0]) < len(xtest[0]):\n",
    "        input_steps = len(xtest[0])\n",
    "        xtrain = sequence.pad_sequences(xtrain, maxlen=input_steps)\n",
    "    else:\n",
    "        input_steps = len(xtrain[0])\n",
    "    \n",
    "    ytrain = sequence.pad_sequences(ytrain, maxlen=input_steps)\n",
    "    ytest = sequence.pad_sequences(ytest, maxlen=input_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------- PREPARE MODELS --------------\n",
    "#create/load model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, Dropout\n",
    "from keras.layers import LSTM, SimpleRNN\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.core import Masking\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "if load_rnn and not load_only_weights:\n",
    "    model = load_model(model_path)\n",
    "    model.load_weights(weights_path)\n",
    "else:\n",
    "    model = Sequential()\n",
    "    if unroll_steps is None and not predict_mode:\n",
    "        #variable length -> mask paddings\n",
    "        #(not implemented for predict_mode)\n",
    "        model.add(Masking(input_shape=(input_steps, input_dim)))\n",
    "        \n",
    "        if use_lstm:\n",
    "            model.add(LSTM(hidden_layers.pop(0), dropout=dropout_prob, recurrent_dropout=dropout_prob, \n",
    "                       return_sequences=use_labels_data))\n",
    "        else:\n",
    "            model.add(SimpleRNN(hidden_layers.pop(0), dropout=dropout_prob, recurrent_dropout=dropout_prob, \n",
    "                       return_sequences=use_labels_data))\n",
    "                     \n",
    "        if use_labels_data:\n",
    "            for k in hidden_layers:\n",
    "                model.add(TimeDistributed(Dense(k, activation=activation)))\n",
    "            model.add(TimeDistributed(Dense(classes, activation='softmax')))\n",
    "        else:\n",
    "            for k in hidden_layers:\n",
    "                model.add(Dense(k, activation=activation))\n",
    "            model.add(Dense(classes, activation='softmax'))\n",
    "        \n",
    "    elif use_rnn:\n",
    "        #recurrent structure: one recurrent cell followed by time distributed layers\n",
    "        if use_lstm:\n",
    "            if predict_mode:\n",
    "                model.add(LSTM(hidden_layers.pop(0), dropout=dropout_prob, recurrent_dropout=dropout_prob, \n",
    "                       batch_input_shape=(1, input_steps, input_dim), return_sequences=use_labels_data, stateful=True))\n",
    "            else:\n",
    "                #hidden_layers.append(classes)\n",
    "                #model.add(LSTM(hidden_layers.pop(0), activation='softmax', dropout=dropout_prob, recurrent_dropout=dropout_prob, \n",
    "                #       input_shape=(input_steps, input_dim), return_sequences=use_labels_data))\n",
    "                model.add(LSTM(hidden_layers.pop(0), dropout=dropout_prob, recurrent_dropout=dropout_prob, \n",
    "                       input_shape=(input_steps, input_dim), return_sequences=use_labels_data))\n",
    "        else:\n",
    "            if predict_mode:\n",
    "                model.add(SimpleRNN(hidden_layers.pop(0), dropout=dropout_prob, recurrent_dropout=dropout_prob, \n",
    "                       batch_input_shape=(1, input_steps, input_dim), return_sequences=use_labels_data, stateful=True))\n",
    "            else:\n",
    "                model.add(SimpleRNN(hidden_layers.pop(0), dropout=dropout_prob, recurrent_dropout=dropout_prob, \n",
    "                       input_shape=(input_steps, input_dim), return_sequences=use_labels_data))\n",
    "                     \n",
    "        if use_labels_data:\n",
    "            for k in hidden_layers:\n",
    "                model.add(TimeDistributed(Dense(k, activation=activation)))\n",
    "            model.add(TimeDistributed(Dense(classes, activation='softmax')))\n",
    "        else:\n",
    "            for k in hidden_layers:\n",
    "                model.add(Dense(k, activation=activation))\n",
    "            model.add(Dense(classes, activation='softmax'))\n",
    "    else:\n",
    "        #purely DNN\n",
    "        if not hidden_layers: #(no hidden layers)\n",
    "            model.add(Dense(classes, activation='softmax', input_shape=(input_steps*input_dim,)))\n",
    "        else:\n",
    "            model.add(Dense(hidden_layers.pop(0), activation=activation, input_shape=(input_steps*input_dim,)))\n",
    "            for k in hidden_layers:\n",
    "                model.add(Dense(k, activation=activation))\n",
    "                if dropout_dense: model.add(Dropout(0.2))\n",
    "            model.add(Dense(classes, activation='softmax'))\n",
    "   \n",
    "        \n",
    "    \n",
    "\n",
    "    if use_sgd: opt = optimizers.SGD(lr=learning_rate)\n",
    "    else: opt = 'adam'\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    if predict_mode or load_only_weights:\n",
    "        #do not save model in predict_mode!\n",
    "        model.load_weights(weights_path)\n",
    "    else:\n",
    "        model.save(model_path)\n",
    "        model.save_weights(weights_path)\n",
    "        \n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#--------- TRAINING/PREDICTION FUNCTIONS --------------\n",
    "if not predict_mode:\n",
    "    #only relevant when training, not in predict mode\n",
    "    \"\"\"\n",
    "    Trains the network for the given epochs and batch_size. The network with the best validation accuracy is saved.\n",
    "    @param epochs: how many epochs to train for\n",
    "    @param batch_size: the batch size to use\n",
    "    \"\"\"\n",
    "    def train(epochs, batch_size):\n",
    "        mcp = ModelCheckpoint(weights_path, monitor='val_acc', save_best_only=True, save_weights_only=True)\n",
    "        model.fit(xtrain, ytrain,\n",
    "                  batch_size=batch_size,\n",
    "                  epochs=epochs,\n",
    "                  validation_data=(xtest, ytest),\n",
    "                  callbacks=[mcp])\n",
    "        score, acc = model.evaluate(xtest, ytest, batch_size=len(xtest))\n",
    "        print('Test score: %s' % score)\n",
    "        print('Test accuracy: %s' % acc)\n",
    "        #model.save(model_path)\n",
    "        #model.save_weights(weights_path)\n",
    "        \n",
    "\"\"\"\n",
    "Test all available data (both train and validation set).\n",
    "@param batch_size: feed batches of this size to reduce memory needed\n",
    "\"\"\"    \n",
    "def test_total(batch_size=None):\n",
    "    if batch_size == None:\n",
    "        acc1 = model.evaluate(xtrain, ytrain, batch_size=len(xtrain), verbose=0)[1]\n",
    "        acc2 = model.evaluate(xtest, ytest, batch_size=len(xtest), verbose=0)[1]\n",
    "    else:\n",
    "        acc1 = 0\n",
    "        num = len(xtrain)\n",
    "        for i in range(0,num,batch_size):\n",
    "            size = min(batch_size, len(xtrain)-i)\n",
    "            xtrain2 = xtrain[i:i+size]\n",
    "            ytrain2 = ytrain[i:i+size]\n",
    "            acc1 += (float(size)/num) * model.evaluate(xtrain2, ytrain2, batch_size=size, verbose=0)[1]\n",
    "\n",
    "        acc2 = 0\n",
    "        num = len(xtest)\n",
    "        for i in range(0,num,batch_size):\n",
    "            size = min(batch_size, len(xtest)-i)\n",
    "            xtrain2 = xtest[i:i+size]\n",
    "            ytrain2 = ytest[i:i+size]\n",
    "            acc2 += (float(size)/num) * model.evaluate(xtrain2, ytrain2, batch_size=size, verbose=0)[1]\n",
    "    acc = acc1*(1.0-test_rate) + acc2*test_rate\n",
    "    print('Train accuracy: %s' % acc1)\n",
    "    print('Test accuracy: %s' % acc2)\n",
    "    print('Total accuracy: %s' % acc)\n",
    "\n",
    "\"\"\"\n",
    "Evaluate the model using the test/validation data.\n",
    "\"\"\"\n",
    "def test():\n",
    "    score, acc = model.evaluate(xtest, ytest, batch_size=len(xtest))\n",
    "    print('Test score: %s' % score)\n",
    "    print('Test accuracy: %s' % acc)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Calculates the per-label accuracies.\n",
    "@param test: if true, the test/validation set is used\n",
    "\"\"\"\n",
    "def per_label_acc(test=True):\n",
    "    if test:\n",
    "        x,y = xtest,ytest\n",
    "    else:\n",
    "        x,y = xtrain,ytrain\n",
    "    accs = [0] * classes\n",
    "    counts = [0] * classes\n",
    "\n",
    "    print_step = len(y)/10\n",
    "    for i in range(len(y)):\n",
    "        acc = model.evaluate(np.array([x[i]]), np.array([y[i]]), batch_size=1, verbose=0)[1]\n",
    "        c = 0\n",
    "        if use_labels_data:\n",
    "            for y_oh in y[i]:\n",
    "                c = np.argmax(y_oh)\n",
    "                accs[c] += acc\n",
    "                counts[c] += 1\n",
    "        else:\n",
    "            c = np.argmax(y[i])\n",
    "            accs[c] += acc\n",
    "            counts[c] += 1\n",
    "        if i%print_step==0:\n",
    "            print('Progress: %s' % (float(i)/len(y)))\n",
    "\n",
    "    acc_total = 0\n",
    "    for i in range(classes):\n",
    "        acc = accs[i]/counts[i]\n",
    "        print('%sx %s: %s' % (counts[i],labels[i],acc))\n",
    "        acc_total += acc*1.0/classes\n",
    "    print('Total test acc: %s' % acc_total)\n",
    "\n",
    "\"\"\"\n",
    "Interface to make feeding data through a recurrent network simpler.\n",
    "@param s: list of data points, if feeding only a single timestep, this needs to be a list with one element\n",
    "@param as_prob: return the output as probabilities instead of argmax\n",
    "@return a list with the output of the network for each of the input steps\n",
    "\"\"\"\n",
    "def feed_seq(s, as_prob=False):\n",
    "    if normalize:\n",
    "        for step in s:\n",
    "            norm(step)\n",
    "    res = model.predict(np.array([s]),batch_size=1)[0]\n",
    "    resarg = []\n",
    "    for r in res:\n",
    "        if as_prob: resarg.append(r)\n",
    "        else: resarg.append(np.argmax(r))\n",
    "    return resarg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small test: compare output of network for one example sample (for each label)\n",
    "if predict_mode:\n",
    "    if False:\n",
    "        import time\n",
    "        start = time.time()\n",
    "        for i in range(10000):\n",
    "            z = [0,0,0,0,0,0]\n",
    "            v = [z]*1\n",
    "            feed_seq(v)\n",
    "        dt = time.time() - start\n",
    "        print('%s hz' % (1/(dt/10000)))\n",
    "\n",
    "    if True:\n",
    "        for key in samples.test:\n",
    "            model.reset_states()\n",
    "            xdata = samples.test[key][0][0]\n",
    "            ydata = samples.labels_test[key][0][0]\n",
    "\n",
    "            res = feed_seq(xdata)\n",
    "\n",
    "            res_predicted = res\n",
    "            res_expected = []\n",
    "            acc = 0\n",
    "            for i in range(len(res)):\n",
    "                res_expected.append(np.argmax(ydata[i]))\n",
    "                if res_predicted[len(res_expected)-1] == res_expected[-1]:\n",
    "                    acc += 1.0\n",
    "            print('%s: %s' % (key, acc/len(res)))\n",
    "            print(res_predicted)\n",
    "            print(res_expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display how many samples are available\n",
    "if True:\n",
    "    for key in labels:\n",
    "        print('%s: %s / %s' % (key, len(samples.data[key]), len(samples.test[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train the network\n",
    "if train_network and not predict_mode:\n",
    "    #train(1000,32)\n",
    "    \n",
    "    #model.optimizer.lr.assign(0.00000000000001)\n",
    "    train(2000,40)\n",
    "    \n",
    "    #per_label_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate model\n",
    "if True:\n",
    "    #if not load_test: test_total(1000)\n",
    "    #elif unroll_steps is not None: test()\n",
    "    #test()\n",
    "    per_label_acc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#live demo\n",
    "%env ROS_HOSTNAME=zinunb\n",
    "%env ROS_IP=$(hostname -I)\n",
    "%env ROS_MASTER_URI=http://pi:11311\n",
    "\n",
    "if live_demo and predict_mode:\n",
    "    import imu_listener as il\n",
    "    #reset()\n",
    "    il.imu_listener(feed_seq,labels,1,5)\n",
    "    print('Exited')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Returns the two most likely labels from the given data (like argmax, but the top two are returned).\n",
    "\"\"\"\n",
    "def argmax2(data):\n",
    "        first = np.argmax(data)\n",
    "        p = data[first]\n",
    "        data[first] = -1 #probabilities are >0\n",
    "        second = np.argmax(data)\n",
    "        data[first] = p\n",
    "        return first,second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test if 30deg network recognizes 15deg\n",
    "if model_type == 11 and use_rnn and True and not predict_mode:\n",
    "    def get_expected(key):\n",
    "        label1,label2 = '',''\n",
    "        \n",
    "        import re\n",
    "        import math\n",
    "        \n",
    "        vals = re.match(r'angle_(\\d*)(?:_(l|r))?', key).groups()\n",
    "        angle = int(vals[0])\n",
    "        left = vals[1]\n",
    "        \n",
    "        angle1 = angle-15\n",
    "        angle2 = angle+15\n",
    "        \n",
    "        if angle1 == 0:\n",
    "            label1 = 'angle_0'\n",
    "        else:\n",
    "            label1 = 'angle_%s_%s' % (angle1,left)\n",
    "            \n",
    "        if angle2 == 180:\n",
    "            label2 = 'angle_180'\n",
    "        else:\n",
    "            label2 = 'angle_%s_%s' % (angle2,left)\n",
    "\n",
    "        return labels.index(label1),labels.index(label2)\n",
    "    \n",
    "    labels2,sample_ids2,filename2 = model_types.get_labels(12)\n",
    "    samples2 = ls.Samples(labels2)\n",
    "\n",
    "    for label in labels2:\n",
    "        samples2.load_samples(label = label, sample_ids = sample_ids2)\n",
    "\n",
    "    samples2.convert_to_input(size = None, accel=accel, gyro=gyro, compass=compass)\n",
    "\n",
    "    if add_absolutes:\n",
    "        samples2.add_absolutes()\n",
    "    if add_moving_average:\n",
    "        samples2.add_moving_average()\n",
    "    samples2.unroll(unroll_steps, overlap_step)\n",
    "    samples2.convert_to_onehot()\n",
    "    \n",
    "    #test on all\n",
    "    for key in samples2.data:\n",
    "        if key in labels: continue\n",
    "        acc = 0\n",
    "        correct = 0\n",
    "        count = len(samples2.data[key])*2\n",
    "        prob_avg = 0\n",
    "        prob_min = 2\n",
    "        prob_max = -1\n",
    "        prob_min_avg = 0\n",
    "        prob_max_avg = 0\n",
    "        prob_1_avg = 0\n",
    "        prob_2_avg = 0\n",
    "        \n",
    "        expected1,expected2 = get_expected(key)\n",
    "        print('%s: %s and %s expected' % (key,labels[expected1],labels[expected2]))\n",
    "        for i in range(len(samples2.data[key])):\n",
    "            xdata = samples2.data[key][i][0]\n",
    "            ydata = samples2.labels_data[key][i][0]\n",
    "\n",
    "            res = model.predict(np.array([xdata]))[0]\n",
    "            r = argmax2(res)\n",
    "            \n",
    "            if expected1 in r: acc += 1\n",
    "            if expected2 in r: acc += 1\n",
    "            if expected1 in r and expected2 in r:\n",
    "                correct += 1\n",
    "                \n",
    "                p1 = res[r[0]]\n",
    "                p2 = res[r[1]]\n",
    "                \n",
    "                prob_min_avg += p2 if p1>p2 else p1\n",
    "                prob_max_avg += p1 if p1>p2 else p2\n",
    "                \n",
    "                if r[0] == expected1:\n",
    "                    prob_1_avg += p1\n",
    "                    prob_2_avg += p2\n",
    "                else:\n",
    "                    prob_1_avg += p2\n",
    "                    prob_2_avg += p1\n",
    "                \n",
    "                for p in [p1,p2]:\n",
    "                    prob_avg += p\n",
    "                    if p < prob_min: prob_min = p\n",
    "                    if p > prob_max: prob_max = p\n",
    "                \n",
    "                \n",
    "        print('Accuracy %s: %s (%s of %s)' % (key,acc/(1.0*count),acc,count))\n",
    "        count = count/2\n",
    "        print('Correct %s: %s (%s of %s)' % (key,correct/(1.0*count),correct,count))\n",
    "        print('Probs (min/max/min_avg/max_avg): %s, %s, %s, %s' % (prob_min, prob_max, prob_min_avg/count, prob_max_avg/count))\n",
    "        print('Probs (avg/avg %s/avg %s): %s, %s, %s' % (labels[expected1],labels[expected2],prob_avg/count,prob_1_avg/count,prob_2_avg/count))\n",
    "        print('====================================================================================================')\n",
    "    \n",
    "        \n",
    "    #test for human eyes\n",
    "    for key in samples2.data:\n",
    "        if key in labels: continue\n",
    "        xdata = samples2.data[key][0][0]\n",
    "        ydata = samples2.labels_data[key][0][0]\n",
    "\n",
    "        res = model.predict(np.array([xdata]))[0]\n",
    "        r1,r2 = argmax2(res)\n",
    "        \n",
    "        print(\"%s: %s and %s (%s and %s)\" % (key,labels[r1],labels[r2],'{0:.0f}%'.format(res[r1]*100),'{0:.0f}%'.format(res[r2]*100)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test if curve network recognizes sm/ml curves\n",
    "if model_type == 0 and not predict_mode and True:\n",
    "    def get_expected(key):\n",
    "        label1,label2 = '',''\n",
    "        \n",
    "        left = '_l' if key.endswith('l') else '_r'\n",
    "        \n",
    "        label1 = 'curve_m'\n",
    "        if key.startswith('curve_sm'):\n",
    "            label2 = 'curve_s'\n",
    "        elif key.startswith('curve_ml'):\n",
    "            label2 = 'curve_l'\n",
    "        \n",
    "        label1 += left\n",
    "        label2 += left\n",
    "        return labels.index(label1),labels.index(label2)\n",
    "    \n",
    "    labels2,sample_ids2,filename2 = model_types.get_labels(6)\n",
    "    print(labels2)\n",
    "    samples2 = ls.load(filename2)\n",
    "    samples2.unroll(None, 1)\n",
    "    samples2.convert_to_onehot()\n",
    "    \n",
    "    #test on all\n",
    "    for key in samples2.data:\n",
    "        if key in labels: continue\n",
    "        acc = 0\n",
    "        correct = 0\n",
    "        count = 0\n",
    "        prob_avg = 0\n",
    "        prob_min = 2\n",
    "        prob_max = -1\n",
    "        prob_min_avg = 0\n",
    "        prob_max_avg = 0\n",
    "        prob_1_avg = 0\n",
    "        prob_2_avg = 0\n",
    "        count_exp1 = 0\n",
    "        count_exp2 = 0\n",
    "        labeldict = {}\n",
    "        for i in range(len(labels)):\n",
    "            labeldict[i] = 0\n",
    "        \n",
    "        expected1,expected2 = get_expected(key)\n",
    "        print('%s: %s and %s expected' % (key,labels[expected1],labels[expected2]))\n",
    "        for i in range(len(samples2.data[key])):\n",
    "            xdata = samples2.data[key][i][0]\n",
    "            ydata = samples2.labels_data[key][i][0]\n",
    "            \n",
    "            model.reset_states()\n",
    "            res_all = model.predict(np.array([xdata]))[0]\n",
    "            for i in range(len(ydata)):\n",
    "                if np.argmax(ydata[i]) != 0:\n",
    "                    res = res_all[i]\n",
    "                    count += 2\n",
    "                    r = argmax2(res)\n",
    "                    \n",
    "                    for k in r:\n",
    "                        labeldict[k] += 1\n",
    "\n",
    "                    if expected1 in r: \n",
    "                        acc += 1\n",
    "                        count_exp1 += 1\n",
    "                    if expected2 in r: \n",
    "                        acc += 1\n",
    "                        count_exp2 += 1\n",
    "                    if expected1 in r and expected2 in r:\n",
    "                        correct += 1\n",
    "\n",
    "                        p1 = res[r[0]]\n",
    "                        p2 = res[r[1]]\n",
    "\n",
    "                        prob_min_avg += p2 if p1>p2 else p1\n",
    "                        prob_max_avg += p1 if p1>p2 else p2\n",
    "\n",
    "                        if r[0] == expected1:\n",
    "                            prob_1_avg += p1\n",
    "                            prob_2_avg += p2\n",
    "                        else:\n",
    "                            prob_1_avg += p2\n",
    "                            prob_2_avg += p1\n",
    "\n",
    "                        for p in [p1,p2]:\n",
    "                            prob_avg += p\n",
    "                            if p < prob_min: prob_min = p\n",
    "                            if p > prob_max: prob_max = p\n",
    "                \n",
    "                \n",
    "        print('Accuracy %s: %s (%s of %s)' % (key,acc/(1.0*count),acc,count))\n",
    "        count = count/2\n",
    "        print('Correct %s: %s (%s of %s)' % (key,correct/(1.0*count),correct,count))\n",
    "        print('Counts %s: %s (%s of %s)' % (labels[expected1],count_exp1/(1.0*count),count_exp1,count))\n",
    "        print('Counts %s: %s (%s of %s)' % (labels[expected2],count_exp2/(1.0*count),count_exp2,count))\n",
    "        print('Probs (min/max/min_avg/max_avg): %s, %s, %s, %s' % (prob_min, prob_max, prob_min_avg/count, prob_max_avg/count))\n",
    "        print('Probs (avg/avg %s/avg %s): %s, %s, %s' % (labels[expected1],labels[expected2],prob_avg/count,prob_1_avg/count,prob_2_avg/count))\n",
    "        for a in labeldict:\n",
    "            print('%s: %s (%s of %s)' % (labels[a],labeldict[a]/(1.0*count),labeldict[a],count))\n",
    "        print('====================================================================================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if predict_mode and True:\n",
    "    #%matplotlib notebook\n",
    "    import matplotlib\n",
    "    import matplotlib.pyplot as plt\n",
    "    DIM = input_dim\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    #ax = fig.add_axes([0.1,0.1,0.75,0.75])\n",
    "    plt.ion()\n",
    "    #fig.show()\n",
    "    fig.canvas.draw()\n",
    "\n",
    "    def draw_data_cutter(key, expected, omit=[], index=0, compare=False):\n",
    "        model.reset_states()\n",
    "        xdata = samples.test[key][index][0]\n",
    "        ydata = samples.labels_test[key][index][0]\n",
    "\n",
    "        res = feed_seq(xdata)\n",
    "\n",
    "        res_predicted = res\n",
    "        res_expected = []\n",
    "        for i in range(len(res)):\n",
    "            res_expected.append(np.argmax(ydata[i]))\n",
    "        \n",
    "        ax.clear()\n",
    "        ax.set_title('%s (%s)' % (key, 'expected' if expected else 'predicted'))\n",
    "        ax.set_xlabel('time')\n",
    "\n",
    "        data2 = np.array(xdata)\n",
    "        data = []\n",
    "        for i in range(DIM): data.append([])\n",
    "        for d in data2:\n",
    "            for i in range(DIM):\n",
    "                if i in omit: continue\n",
    "                data[i].append(d[i])\n",
    "\n",
    "        for i in range(DIM):\n",
    "            if i in omit: continue\n",
    "            if i<3 and DIM>3:\n",
    "                label = 'accel %s' % ('xyz'[i])\n",
    "            else:\n",
    "                label = 'gyro %s' % ('xyz'[i-3])\n",
    "            ax.plot(range(len(data[i])),data[i], label=label)\n",
    "        \n",
    "        if compare:\n",
    "            if expected:\n",
    "                span_data = res_expected\n",
    "                key_expected = labels.index(key)\n",
    "            else:\n",
    "                key_expected = labels.index(key)\n",
    "                span_data = res_predicted\n",
    "                for i in range(len(span_data)):\n",
    "                    if span_data[i] != res_expected[i]:\n",
    "                        span_data[i] = -1 #different\n",
    "                    elif res_expected[i] == 0 and key_expected != 0:\n",
    "                        span_data[i] = 0 #same, but straight in a non straight sample\n",
    "                    else:\n",
    "                        span_data[i] = 1 #same\n",
    "\n",
    "                key_expected = 1 \n",
    "        else:\n",
    "            span_data = res_expected if expected else res_predicted\n",
    "            key_expected = labels.index(key)\n",
    "            \n",
    "            \n",
    "        start_i = 0\n",
    "        current_type = 0\n",
    "        for i in range(len(span_data)):\n",
    "            if current_type != span_data[i]:\n",
    "                if current_type == key_expected:\n",
    "                    ax.axvspan(start_i, i, color='green', alpha=0.1)\n",
    "                elif current_type != key_expected and current_type != 0:\n",
    "                    ax.axvspan(start_i, i, color='red', alpha=0.1)\n",
    "                current_type = span_data[i]\n",
    "                start_i = i\n",
    "\n",
    "        if current_type == key_expected:\n",
    "            ax.axvspan(start_i, len(span_data), color='green', alpha=0.1)\n",
    "        elif current_type != key_expected and current_type != 0:\n",
    "            ax.axvspan(start_i, len(span_data), color='red', alpha=0.1)\n",
    "\n",
    "        \n",
    "        ax.legend(loc='lower left')\n",
    "        fig.canvas.draw()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save image of the predicition for a single sample per label\n",
    "if predict_mode and True:\n",
    "    omit = [0,1,2] if model_type==0 else []\n",
    "    for label in labels:\n",
    "        draw_data_cutter(label,True,omit)\n",
    "        plt.savefig('data-%s-%s.png' % (label, 'expected'),pad_inches=0,bbox_inches='tight')\n",
    "        draw_data_cutter(label,False,omit)\n",
    "        plt.savefig('data-%s-%s.png' % (label, 'predicted'),pad_inches=0,bbox_inches='tight')\n",
    "        print('Saved %s' % label)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save image of the prediction for all test samples\n",
    "if predict_mode and load_test and False:\n",
    "    omit = [0,1,2] if model_type==0 else []\n",
    "    for label in labels:\n",
    "        for index in range(20):\n",
    "            draw_data_cutter(label,True,omit,index)\n",
    "            plt.savefig('test/data-%s-%s-%s.png' % (label, index, 'expected'),pad_inches=0,bbox_inches='tight')\n",
    "            draw_data_cutter(label,False,omit,index)\n",
    "            plt.savefig('test/data-%s-%s-%s.png' % (label, index, 'predicted'),pad_inches=0,bbox_inches='tight')\n",
    "            print('Saved %s' % label)\n",
    "    print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
